#!/usr/bin/python
# Author: Jonathan Howard
# Description: OMG! It's like python, but like, totally casual!

import os
from subprocess import *
import sys
import tokenize

like_python_tokens = ['omg','so','like','totally','right','toootally',
                      'friggin','fuckin','dude','man','bro','broheim','broseph',
                      'lol','rofl','teh','ohai','plz',
                      'yo','homey','homeboy','sup','dog','girl','ma','biatch',
                          'ho','shit','shiiit',
                      'wicked','hella','anyways',
                      'just','hey','yeah','ok','um','uh','ah','actually',
                          'something',
                     ]

like_python_mappings = {'tellem':'print', 'holla':'print', 'srsly':'finally',
                        'rockon':'continue', 'an':'and', 'mostdef':'assert',
                        'fuckit':'exit'
                       }

def handle_input():
  if len(sys.argv) == 2:
    return sys.argv[1]
  else:
    print "Usage: likepython path/to/file.lp"
    exit()

def py_map(token):
  return token if token not in like_python_mappings else like_python_mappings[token]

def main():
    # Parse input file for tokens
    input_file = handle_input()
    file = open(input_file)
    tokens = tokenize.generate_tokens(file.readline)

    # Remove likepython tokens, leaving valid python temp file behind.
    py_tokens = [(type,py_map(token)) for (type,token, _, _, _) in tokens if token not in like_python_tokens]
    py = tokenize.untokenize(py_tokens)
    output_filename = input_file + ".py"
    output_file = open(output_filename, 'w')
    output_file.write(py) 
    output_file.close()

    # Run through python and return stdout
    call(["python", output_filename])

    # Remove temp file
    os.remove(output_filename)    

if __name__ == "__main__":
  main()
